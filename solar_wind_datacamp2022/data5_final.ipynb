{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e03cf82-e789-4fcf-9e6e-a00d293acfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ee874d-0cee-4320-aa17-70102bb09d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025fd371-1487-4bba-8f32-1d95bec3ae08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "\n",
    "data_train, labels_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b8f063-b89b-4392-ba74-c40dee0daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_test_data\n",
    "\n",
    "data_test, labels_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0354f142-b08f-4c57-b192-0aba3953b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_train.copy()\n",
    "df['target'] = labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dadfb0-e683-451d-92e4-14ec77b4e9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8f9bf7-657b-4b2d-872d-7aa3fdd3bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df['Beta'],model='additive',period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2e6d4d-a69b-42d7-9f2a-4d7fd64a66b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52bc5331-5da4-4d66-ac01-ca690a90ddcf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997-10-01 00:00:00     7.641340\n",
       "1997-10-01 00:10:00     9.149856\n",
       "1997-10-01 00:20:00    11.924199\n",
       "1997-10-01 00:30:00    16.032987\n",
       "1997-10-01 00:40:00    10.253789\n",
       "                         ...    \n",
       "2007-12-31 23:10:00     1.304273\n",
       "2007-12-31 23:20:00     0.982693\n",
       "2007-12-31 23:30:00     0.989657\n",
       "2007-12-31 23:40:00     0.958408\n",
       "2007-12-31 23:50:00     0.912270\n",
       "Name: trend, Length: 509834, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fbb9d-08b4-4efa-be28-17f9be03e912",
   "metadata": {},
   "source": [
    "### diff features\n",
    "This is the easiest method and involves calculating the difference between consecutive elements. It stabilizes the mean and reduces the impact of trends and seasonal behavior, leaving the model free to focus on predicting one point after another.\n",
    "\n",
    "Click here for more informations : https://h2o.ai/blog/an-introduction-to-time-series-modeling-time-series-preprocessing-and-feature-engineering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc45636-40be-4cc8-b31a-ec56f9a39d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beta_diff'] = df['Beta'].diff(periods=144)\n",
    "df['RmsBob_diff'] = df['RmsBob'].diff(periods=144)\n",
    "df['Range F 1_diff'] = df['Range F 1'].diff(periods=144)\n",
    "df['Range F 4_diff'] = df['Range F 4'].diff(periods=144)\n",
    "df['Range F 13_diff'] = df['Range F 13'].diff(periods=144)\n",
    "\n",
    "df['Beta_diff_1'] = df['Beta'].diff(periods=1)\n",
    "df['RmsBob_diff_1'] = df['RmsBob'].diff(periods=1)\n",
    "df['Range F 1_diff_1'] = df['Range F 1'].diff(periods=1)\n",
    "df['Range F 4_diff_1'] = df['Range F 4'].diff(periods=1)\n",
    "df['Range F 13_diff_1'] = df['Range F 13'].diff(periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1efa1-b0d0-40aa-8348-ec47366f48ab",
   "metadata": {},
   "source": [
    "### shift features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10943481-df66-44e8-907e-6091b9135280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beta_d-1'] = df['Beta'].shift(144)\n",
    "df['Pdyn_d-1'] = df['Pdyn'].shift(144)\n",
    "df['Vx_d-1'] = df['Vx'].shift(144)\n",
    "\n",
    "df['Beta_t-1'] = df['Beta'].shift(1)\n",
    "df['RmsBob_t-1'] = df['RmsBob'].shift(1)\n",
    "df['Vx_t-1'] = df['Vx'].shift(1)\n",
    "\n",
    "df['Vx_m-1'] = df['Vx'].shift(144*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c1a2b-6940-44d3-a2c7-80c0ccf9d6d8",
   "metadata": {},
   "source": [
    "### freq_fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7725e1-7bb5-4154-b2a6-94380717e738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain the frequencies\n",
    "df['freq_fourier'] = np.fft.fftfreq(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cef444-34ab-44c4-9e1f-493ae5d0d83f",
   "metadata": {},
   "source": [
    "### rolling_windows features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f90400-b1c2-4eb3-b650-fa615f123773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beta_rw2h_mean'] = df['Beta'].rolling('2h', center=False).mean().ffill().bfill().astype(df['Beta'].dtype)\n",
    "df['Beta_rw1h_mean'] = df['Beta'].rolling('1h', center=False).mean().ffill().bfill().astype(df['Beta'].dtype)\n",
    "df['Beta_rw12h_mean'] = df['Beta'].rolling('12h', center=False).mean().ffill().bfill().astype(df['Beta'].dtype)\n",
    "df['Beta_rw1h_std'] = df['Beta'].rolling('1h', center=False).std().ffill().bfill().astype(df['Beta'].dtype)\n",
    "df['Beta_rw2h_std'] = df['Beta'].rolling('2h', center=False).std().ffill().bfill().astype(df['Beta'].dtype)\n",
    "df['Beta_rw24h_mean'] = df['Beta'].rolling('24h', center=False).mean().ffill().bfill().astype(df['Beta'].dtype)\n",
    "\n",
    "\n",
    "\n",
    "df['RmsBob_rw12h_mean'] = df['RmsBob'].rolling('12h', center=False).mean().ffill().bfill().astype(df['RmsBob'].dtype)\n",
    "df['RmsBob_rw2h_mean'] = df['RmsBob'].rolling('2h', center=False).mean().ffill().bfill().astype(df['RmsBob'].dtype)\n",
    "df['RmsBob_rw24h_mean'] = df['RmsBob'].rolling('24h', center=False).mean().ffill().bfill().astype(df['RmsBob'].dtype)\n",
    "df['RmsBob_rw12h_std'] = df['RmsBob'].rolling('12h', center=False).std().ffill().bfill().astype(df['RmsBob'].dtype)\n",
    "df['RmsBob_rw1h_mean'] = df['RmsBob'].rolling('1h', center=False).mean().ffill().bfill().astype(df['RmsBob'].dtype)\n",
    "\n",
    "df['B_rw24h_mean'] = df['B'].rolling('24h', center=False).mean().ffill().bfill().astype(df['B'].dtype)\n",
    "df['B_rw24h_std'] = df['B'].rolling('24h', center=False).std().ffill().bfill().astype(df['B'].dtype)\n",
    "df['B_rw12h_mean'] = df['B'].rolling('12h', center=False).mean().ffill().bfill().astype(df['B'].dtype)\n",
    "\n",
    "df['Range F 7_rw1w_std'] = df['Range F 7'].rolling('168h', center=False).std().ffill().bfill().astype(df['Range F 7'].dtype)\n",
    "df['Range F 7_rw24h_std'] = df['Range F 7'].rolling('24h', center=False).std().ffill().bfill().astype(df['Range F 7'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ef2f9-5c80-4e3f-9905-04e336e9a34c",
   "metadata": {},
   "source": [
    "### time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ba15b8-577c-47c1-bc79-dface9ee18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df.index.hour\n",
    "df['dayofyear'] = df.index.day_of_year\n",
    "df['month'] = df.index.month\n",
    "df['year'] = df.index.year\n",
    "df['week'] = df.index.week\n",
    "df['dayofweek'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecc419-6fed-4868-a13d-0c6f4a1a3ad4",
   "metadata": {},
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bc18b3-2df1-418e-9629-0b32cdfa7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['Beta_rw2h_mean', 'Beta','Beta_rw1h_mean','Beta_rw12h_mean','RmsBob_rw12h_mean','Beta_rw1h_std','RmsBob_rw2h_mean'\n",
    "              ,'Beta_rw2h_std','B_rw24h_mean','B_rw24h_std','B_rw12h_mean','RmsBob_rw24h_mean','Vx','Range F 7_rw1w_std',\n",
    "              'Beta_rw24h_mean','RmsBob_rw12h_std','RmsBob_rw1h_mean','Range F 7_rw24h_std','Range F 4','Beta_t-1',\n",
    "              'RmsBob_t-1','Pdyn_d-1','Pdyn','Vx_d-1','Vx_t-1','Vx_m-1','Range F 4_diff','Range F 1_diff','Beta_diff',\n",
    "              'Range F 13_diff','RmsBob_diff','Beta_d-1','Range F 1','Range F 9','Vth','Vy','V','dayofyear','week','year',\n",
    "              'dayofweek','month','hour','freq_fourier','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83334f3d-adbe-4bfe-90fd-272ee4a8fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.copy()\n",
    "final_df = final_df[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d62851-6f57-4c61-a4f8-ba8622b1d0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7849b92c-ef86-4050-b616-76676a522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Séparer les données en X et y\n",
    "X = df.drop(columns=['target'], axis=1).fillna(0)\n",
    "y = df['target']\n",
    "#X2 = X.fillna(0)\n",
    "# Perform clustering to create balanced subsets\n",
    "kmeans = KMeans(n_clusters=2, max_iter = 20)\n",
    "#cluster_labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cb942-572b-41c1-b504-17382549586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a8c10-d9b6-4bf4-9172-1b771702c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train base classifiers on each balanced subset\n",
    "base_classifiers = []\n",
    "for i in range(10):\n",
    "    X_cluster = X[cluster_labels == i]\n",
    "    y_cluster = y[cluster_labels == i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cluster, y_cluster, test_size=0.3)\n",
    "    clf = LogisticRegression()\n",
    "    model = make_pipeline(StandardScaler(), clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy of base classifier {}: {}'.format(i, accuracy_score(y_test, y_pred)))\n",
    "    base_classifiers.append(clf)\n",
    "\n",
    "# Implement self-paced learning to select a subset of base classifiers\n",
    "selected_classifiers = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "while len(selected_classifiers) < 5:\n",
    "    scores = []\n",
    "    for clf in base_classifiers:\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores.append(accuracy_score(y_test, y_pred))\n",
    "    scores = np.array(scores)\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    selected_indices = indices[:len(selected_classifiers)+1]\n",
    "    selected_classifiers = [base_classifiers[i] for i in selected_indices]\n",
    "\n",
    "# Combine selected base classifiers into an ensemble classifier\n",
    "def ensemble_predict(X):\n",
    "    y_preds = []\n",
    "    for clf in selected_classifiers:\n",
    "        y_pred = clf.predict(X)\n",
    "        y_preds.append(y_pred)\n",
    "    y_preds = np.array(y_preds)\n",
    "    y_ensemble = np.mean(y_preds, axis=0)\n",
    "    return y_ensemble\n",
    "\n",
    "y_pred = ensemble_predict(X_test)\n",
    "print('Accuracy of ensemble classifier: {}'.format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "902a0fe6-97f0-46c5-8a07-bd51ba04a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8733229769806524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:20, 80.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29671628453108295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     71206\n",
      "           1       0.86      0.26      0.40     13766\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.87      0.63      0.66     84972\n",
      "weighted avg       0.87      0.87      0.84     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.626\n",
      "0.8776067410441086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:23, 140.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2995228620581445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     69883\n",
      "           1       0.71      0.53      0.61     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.80      0.74      0.77     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.743\n",
      "0.939109353669444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [09:05, 205.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16962868825282768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     77546\n",
      "           1       0.78      0.42      0.55      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.87      0.70      0.76     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.704\n",
      "0.9549380972555666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [15:25, 274.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1347021609671843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.79      0.63      0.70      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.88      0.81      0.84     84972\n",
      "weighted avg       0.95      0.95      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.809\n",
      "0.9738149037329944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [23:40, 284.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08344491022864237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     81981\n",
      "           1       0.81      0.34      0.47      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.89      0.67      0.73     84972\n",
      "weighted avg       0.97      0.97      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# Séparer les données en X et y\n",
    "X = final_df.drop(columns=['target'], axis=1)\n",
    "y = final_df['target']\n",
    "X2 = X.fillna(0)\n",
    "\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tqdm(tscv.split(X2)):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    classifier = RandomForestClassifier(max_depth=100, random_state=42)#LogisticRegression()\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cb7f599-bbf9-42d0-a9cf-53f321f7d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_features_importance(model, cols):\n",
    "    '''\n",
    "    Plot feature_importance from a random forest model\n",
    "\n",
    "    Input:\n",
    "    model (MODEL_TYPE) : Model for which to compute the feature importance\n",
    "    cols (list) : input DataFrame with true labels\n",
    "\n",
    "    Output:\n",
    "    None\n",
    "    '''\n",
    "    # get feature importance from model\n",
    "    importances = model.feature_importances_\n",
    "    forest_importances = pd.Series(importances, index=cols).sort_values(ascending=False)\n",
    "    # plot results\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    forest_importances.plot.bar(ax=ax)\n",
    "    ax.set_title(\"Feature importances\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e726c16e-0e26-4e0a-b8ff-a5e2c153d554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_features_importance(classifier, cols=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "625eaea2-d0f9-485d-8772-36cc2dfa81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['target','month','year','Vy','dayofweek', 'Beta_d-1','Range F 4_diff','Range F 13_diff','Range F 1_diff', 'Range F 1','hour','Beta_diff','RmsBob_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3958be03-5af0-453f-82f4-208d40e69cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856011391987949\n",
      "0.5005842652418828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     71206\n",
      "           1       0.88      0.13      0.22     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.87      0.56      0.57     84972\n",
      "weighted avg       0.86      0.86      0.81     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.563\n",
      "0.8728640022595678\n",
      "0.346519265350287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     69883\n",
      "           1       0.75      0.43      0.54     15089\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.82      0.70      0.73     84972\n",
      "weighted avg       0.86      0.87      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.698\n",
      "0.9381560984794991\n",
      "0.15567391748548448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     77546\n",
      "           1       0.72      0.48      0.57      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.84      0.73      0.77     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.730\n",
      "0.9557501294544085\n",
      "0.11605465378887939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.76      0.70      0.73      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.87      0.84      0.85     84972\n",
      "weighted avg       0.95      0.96      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.840\n",
      "0.9736736807418914\n",
      "0.06772814792453402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     81981\n",
      "           1       0.74      0.39      0.51      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.86      0.69      0.75     84972\n",
      "weighted avg       0.97      0.97      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = final_df.drop(columns=cols_to_drop, axis=1)\n",
    "y = final_df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier()\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a372af-04e0-4900-8304-8865f67f04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86315492162124\n",
      "0.4739507230865418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     71206\n",
      "           1       0.89      0.18      0.30     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.87      0.59      0.61     84972\n",
      "weighted avg       0.87      0.86      0.82     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.587\n",
      "0.8740290919361672\n",
      "0.35033824763322435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     69883\n",
      "           1       0.80      0.39      0.52     15089\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.84      0.68      0.73     84972\n",
      "weighted avg       0.87      0.87      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.684\n",
      "0.938991667843525\n",
      "0.15366550553607206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     77546\n",
      "           1       0.71      0.52      0.60      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.83      0.75      0.78     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.747\n",
      "0.9550440144988938\n",
      "0.11509460273155088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.75      0.70      0.72      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.86      0.84      0.85     84972\n",
      "weighted avg       0.95      0.96      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.838\n",
      "0.971319964223509\n",
      "0.07755542635100507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     81981\n",
      "           1       0.90      0.21      0.34      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.94      0.60      0.66     84972\n",
      "weighted avg       0.97      0.97      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = final_df.drop(columns=cols_to_drop, axis=1)\n",
    "y = final_df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier()\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5598714a-7b0c-4231-9f7b-abeb2fe33927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509834, 34)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_train.copy()\n",
    "df['target'] = labels_train\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af10eda0-b5b9-42f4-a88c-498ee41158ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851268653203408\n",
      "0.28725729516608145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     71206\n",
      "           1       0.70      0.52      0.59     13766\n",
      "\n",
      "    accuracy                           0.89     84972\n",
      "   macro avg       0.80      0.74      0.76     84972\n",
      "weighted avg       0.88      0.89      0.88     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.736\n",
      "0.8624605752483171\n",
      "0.3438494831791435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     69883\n",
      "           1       0.67      0.45      0.54     15089\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.78      0.70      0.73     84972\n",
      "weighted avg       0.85      0.86      0.85     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.699\n",
      "0.9313773949065575\n",
      "0.18612147209597016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     77546\n",
      "           1       0.69      0.39      0.50      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.82      0.69      0.73     84972\n",
      "weighted avg       0.92      0.93      0.92     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.689\n",
      "0.9471119898319447\n",
      "0.15194905919248516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     77756\n",
      "           1       0.73      0.60      0.66      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.85      0.79      0.81     84972\n",
      "weighted avg       0.94      0.95      0.94     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.788\n",
      "0.9684955044014499\n",
      "0.09509832672808588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     81981\n",
      "           1       0.65      0.22      0.33      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.81      0.61      0.66     84972\n",
      "weighted avg       0.96      0.97      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.610\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier()\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301dce88-4dce-4a1a-acbb-baef8b65c29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de75f5d-d360-4dc0-abba-66e9a56b1cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2343b479-f305-409a-8a39-d2dd33ec5237",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m gsearch \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclassifier, cv\u001b[38;5;241m=\u001b[39mtscv,\n\u001b[1;32m     22\u001b[0m                         param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m], refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mgsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "#parameters to tune\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    #'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "'''n_jobs=5, \n",
    "cv=5, scoring=’f1_micro’,\n",
    "verbose=2, refit=True'''\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gsearch = GridSearchCV(estimator=classifier, cv=tscv,\n",
    "                        param_grid=param_grid, scoring=['f1'], refit=False, verbose=2, n_jobs=5)\n",
    "gsearch.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc4b235b-2d67-427c-89ff-a3e709576141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............max_iter=1000, penalty=l2, solver=sag; total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............max_iter=1000, penalty=l2, solver=sag; total time=10.1min\n",
      "[CV] END ..............max_iter=1000, penalty=l2, solver=sag; total time= 4.0min\n",
      "[CV] END .............max_iter=1000, penalty=l2, solver=saga; total time= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=LogisticRegression(), n_jobs=5,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [1000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             refit=False,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;log_loss&#x27;: make_scorer(log_loss)},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=LogisticRegression(), n_jobs=5,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [1000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             refit=False,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;log_loss&#x27;: make_scorer(log_loss)},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=LogisticRegression(), n_jobs=5,\n",
       "             param_grid=[{'max_iter': [1000], 'penalty': ['l2'],\n",
       "                          'solver': ['sag', 'saga']}],\n",
       "             refit=False,\n",
       "             scoring={'f1': make_scorer(f1_score),\n",
       "                      'log_loss': make_scorer(log_loss)},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "#parameters to tune\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l2'], #l2\n",
    "    #'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['sag','saga'],\n",
    "    'max_iter' : [1000] #1000\n",
    "    }\n",
    "]\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "logloss_score = make_scorer(log_loss)\n",
    "f1_score_score = make_scorer(f1_score)\n",
    "\n",
    "'''n_jobs=5, \n",
    "cv=5, scoring=’f1_micro’,\n",
    "verbose=2, refit=True'''\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gsearch = GridSearchCV(estimator=classifier, cv=tscv,\n",
    "                        param_grid=param_grid, scoring={'log_loss':logloss_score,'f1':f1_score_score}, refit=False, verbose=2, n_jobs=5)\n",
    "gsearch.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3109478d-3da1-46eb-8329-6ce032498e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['rank_test_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2501bace-516c-4be9-acc5-427d47cc6a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............max_iter=1000, penalty=l2, solver=sag; total time= 6.2min\n",
      "[CV] END .............max_iter=1000, penalty=l2, solver=saga; total time= 7.6min\n",
      "[CV] END ..............max_iter=1000, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END .............max_iter=1000, penalty=l2, solver=saga; total time= 2.1min\n",
      "[CV] END .............max_iter=1000, penalty=l2, solver=saga; total time= 4.2min\n",
      "[CV] END .............max_iter=1000, penalty=l2, solver=saga; total time= 9.5min\n"
     ]
    }
   ],
   "source": [
    "gsearch.cv_results_['rank_test_f1']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "759b9919-31b6-485b-b737-7d3ab4164fe9",
   "metadata": {},
   "source": [
    "1,5,9,13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79fb6466-40f6-4341-bf97-05db52ac74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['params'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55d484e1-9812-4331-8842-cd5c60bf3eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['params'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca2044a7-f205-43e3-9481-244fa20a86ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 2500, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['params'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df1107b6-dcf2-4cde-b213-82ead21cad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 5000, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['params'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509630f-785e-41d5-8ee4-9f119728706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "#parameters to tune\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "'''n_jobs=5, \n",
    "cv=5, scoring=’f1_micro’,\n",
    "verbose=2, refit=True'''\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gsearch = GridSearchCV(estimator=classifier, cv=tscv,\n",
    "                        param_grid=param_grid, scoring=['f1'], refit=False, verbose=2, n_jobs=5)\n",
    "gsearch.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b106f890-397b-426b-bfc6-8e3871e45449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509834, 74)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add9827f-6b3f-4991-a78e-3f6399306764",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "------------- Nearest Neighbors -------------\n",
      "0.8587770088970484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:44, 44.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.307067612665758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     71206\n",
      "           1       0.64      0.30      0.41     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.76      0.63      0.66     84972\n",
      "weighted avg       0.84      0.86      0.84     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.634\n",
      "0.8217648166454832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:04, 65.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.191404860902615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     69883\n",
      "           1       0.50      0.33      0.40     15089\n",
      "\n",
      "    accuracy                           0.82     84972\n",
      "   macro avg       0.68      0.63      0.65     84972\n",
      "weighted avg       0.80      0.82      0.81     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.630\n",
      "0.9114296474132656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:52, 84.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5128155159049896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     77546\n",
      "           1       0.49      0.26      0.34      7426\n",
      "\n",
      "    accuracy                           0.91     84972\n",
      "   macro avg       0.71      0.62      0.64     84972\n",
      "weighted avg       0.89      0.91      0.90     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.615\n",
      "0.9016381866967942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:13, 106.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7550379760683206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     77756\n",
      "           1       0.41      0.39      0.40      7216\n",
      "\n",
      "    accuracy                           0.90     84972\n",
      "   macro avg       0.68      0.67      0.67     84972\n",
      "weighted avg       0.90      0.90      0.90     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.668\n",
      "0.9503365814621287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [09:20, 112.02s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3942750459239275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     81981\n",
      "           1       0.25      0.20      0.22      2991\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.61      0.59      0.60     84972\n",
      "weighted avg       0.95      0.95      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.590\n",
      "\n",
      "\n",
      "\n",
      "------------- Random Forest -------------\n",
      "0.8922703949536318\n",
      "0.2978200749810595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     71206\n",
      "           1       0.80      0.44      0.57     13766\n",
      "\n",
      "    accuracy                           0.89     84972\n",
      "   macro avg       0.85      0.71      0.76     84972\n",
      "weighted avg       0.89      0.89      0.88     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.712\n",
      "0.8719813585651744\n",
      "0.3157477275463055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     69883\n",
      "           1       0.68      0.52      0.59     15089\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.79      0.73      0.76     84972\n",
      "weighted avg       0.86      0.87      0.86     84972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of the default model is 0.733\n",
      "0.4503954243750883\n",
      "1.3304888103420247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57     77546\n",
      "           1       0.14      0.98      0.24      7426\n",
      "\n",
      "    accuracy                           0.45     84972\n",
      "   macro avg       0.57      0.69      0.40     84972\n",
      "weighted avg       0.92      0.45      0.54     84972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:09,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of the default model is 0.690\n",
      "0.9535140987619452\n",
      "0.15825941216568543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     77756\n",
      "           1       0.75      0.68      0.71      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.86      0.83      0.84     84972\n",
      "weighted avg       0.95      0.95      0.95     84972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:16,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of the default model is 0.832\n",
      "0.9753801252177188\n",
      "0.07918735236001834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:25,  5.16s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     81981\n",
      "           1       0.77      0.43      0.55      2991\n",
      "\n",
      "    accuracy                           0.98     84972\n",
      "   macro avg       0.87      0.71      0.77     84972\n",
      "weighted avg       0.97      0.98      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.713\n",
      "\n",
      "\n",
      "\n",
      "------------- HistGradientBoostingClassifier -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [04:41, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8855505342936497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Afficher la précision\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, y_pred))\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_loss(y_test, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X_test)))\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe balanced accuracy of the default model is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbalanced_accuracy_score(y_test, y_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     26\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[1;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:47\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     26\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[1;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:829\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    830\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when  probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m         )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Logistic Regression\"\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"HistGradientBoostingClassifier\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    LogisticRegression(),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    HistGradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "i=0\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\\n-------------\", names[i],'-------------')\n",
    "    \n",
    "    # Boucle sur les plis\n",
    "    for train_index, test_index in tqdm(tscv.split(X2)):\n",
    "        X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "\n",
    "        # Entrainer un modèle sur le jeu d'entraînement\n",
    "\n",
    "        model =make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "        #model.set_params(class_weight='balanced_subsample')\n",
    "\n",
    "        model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "        # Prédire sur le jeu de test\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Afficher la précision\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"The balanced accuracy of the default model is \"\n",
    "              f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb9608-6710-44bd-9e50-e1e0a5abf598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae6bebd-5cbd-4ccf-adff-8aea88140f69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "0.85964788400885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:56, 56.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44515100996950435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     71206\n",
      "           1       0.85      0.16      0.27     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.86      0.58      0.60     84972\n",
      "weighted avg       0.86      0.86      0.82     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.578\n",
      "0.8654851009744386\n",
      "0.3121842660454226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:53, 56.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     69883\n",
      "           1       0.64      0.54      0.59     15089\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.77      0.74      0.75     84972\n",
      "weighted avg       0.86      0.87      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.738\n",
      "0.940862872475639\n",
      "0.15724027548848252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:08, 65.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     77546\n",
      "           1       0.79      0.44      0.56      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.87      0.71      0.77     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.713\n",
      "0.9526314550675516\n",
      "0.15081005079577597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:44, 77.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     77756\n",
      "           1       0.74      0.68      0.71      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.86      0.83      0.84     84972\n",
      "weighted avg       0.95      0.95      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.829\n",
      "0.9764628348161747\n",
      "0.07198463894794416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [06:14, 74.97s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     81981\n",
      "           1       0.81      0.43      0.57      2991\n",
      "\n",
      "    accuracy                           0.98     84972\n",
      "   macro avg       0.89      0.72      0.78     84972\n",
      "weighted avg       0.97      0.98      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.715\n",
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "0.8379936920397307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:56, 56.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4879198929128028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91     71206\n",
      "           1       0.00      0.00      0.00     13766\n",
      "\n",
      "    accuracy                           0.84     84972\n",
      "   macro avg       0.42      0.50      0.46     84972\n",
      "weighted avg       0.70      0.84      0.76     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.500\n",
      "0.8579649766982065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:50, 90.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6465322493494637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     69883\n",
      "           1       0.81      0.26      0.39     15089\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.84      0.62      0.66     84972\n",
      "weighted avg       0.85      0.86      0.83     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.623\n",
      "0.9312008661676787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:55, 133.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388486194783839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     77546\n",
      "           1       0.82      0.28      0.41      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.87      0.63      0.69     84972\n",
      "weighted avg       0.92      0.93      0.92     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.635\n",
      "0.9434754978110437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [09:59, 177.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6513976990600884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     77756\n",
      "           1       0.67      0.65      0.66      7216\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.82      0.81      0.81     84972\n",
      "weighted avg       0.94      0.94      0.94     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.808\n",
      "0.9685425787318176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [15:12, 182.54s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207159034524456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     81981\n",
      "           1       0.92      0.12      0.21      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.94      0.56      0.60     84972\n",
      "weighted avg       0.97      0.97      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.558\n",
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "0.49406863437367604\n",
      "9.906919156593707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.41      0.58     71206\n",
      "           1       0.23      0.92      0.37     13766\n",
      "\n",
      "    accuracy                           0.49     84972\n",
      "   macro avg       0.60      0.67      0.47     84972\n",
      "weighted avg       0.85      0.49      0.54     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.667\n",
      "0.29060160994209855\n",
      "23.197437627025128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.14      0.25     69883\n",
      "           1       0.20      0.97      0.33     15089\n",
      "\n",
      "    accuracy                           0.29     84972\n",
      "   macro avg       0.58      0.56      0.29     84972\n",
      "weighted avg       0.82      0.29      0.26     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.557\n",
      "0.33884102998634846\n",
      "19.30294319740796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.28      0.44     77546\n",
      "           1       0.11      0.96      0.20      7426\n",
      "\n",
      "    accuracy                           0.34     84972\n",
      "   macro avg       0.55      0.62      0.32     84972\n",
      "weighted avg       0.91      0.34      0.42     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.620\n",
      "0.20011297839288236\n",
      "24.124220451218267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.13      0.23     77756\n",
      "           1       0.09      0.95      0.17      7216\n",
      "\n",
      "    accuracy                           0.20     84972\n",
      "   macro avg       0.53      0.54      0.20     84972\n",
      "weighted avg       0.89      0.20      0.22     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.539\n",
      "0.1807771971943699\n",
      "23.75332463839094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:08,  1.71s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.26     81981\n",
      "           1       0.04      1.00      0.08      2991\n",
      "\n",
      "    accuracy                           0.18     84972\n",
      "   macro avg       0.52      0.57      0.17     84972\n",
      "weighted avg       0.97      0.18      0.26     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.574\n",
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "0.3580002824459822\n",
      "19.355686149617135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.25      0.40     71206\n",
      "           1       0.19      0.90      0.31     13766\n",
      "\n",
      "    accuracy                           0.36     84972\n",
      "   macro avg       0.56      0.58      0.36     84972\n",
      "weighted avg       0.81      0.36      0.38     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.576\n",
      "0.2547780445323165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.910382160854493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.10      0.18     69883\n",
      "           1       0.19      0.98      0.32     15089\n",
      "\n",
      "    accuracy                           0.25     84972\n",
      "   macro avg       0.57      0.54      0.25     84972\n",
      "weighted avg       0.81      0.25      0.20     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.537\n",
      "0.9125947370898649\n",
      "3.1504050007175666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     77546\n",
      "           1       0.00      0.00      0.00      7426\n",
      "\n",
      "    accuracy                           0.91     84972\n",
      "   macro avg       0.46      0.50      0.48     84972\n",
      "weighted avg       0.83      0.91      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.500\n",
      "0.1362213435013887\n",
      "29.984783898367667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:10,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.06      0.11     77756\n",
      "           1       0.09      0.97      0.16      7216\n",
      "\n",
      "    accuracy                           0.14     84972\n",
      "   macro avg       0.52      0.51      0.14     84972\n",
      "weighted avg       0.88      0.14      0.12     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.514\n",
      "0.12195782139999059\n",
      "29.51894274801228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.07s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17     81981\n",
      "           1       0.04      0.99      0.07      2991\n",
      "\n",
      "    accuracy                           0.12     84972\n",
      "   macro avg       0.52      0.54      0.12     84972\n",
      "weighted avg       0.96      0.12      0.16     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.541\n",
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "0.8556465659275997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48088284597711073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     71206\n",
      "           1       0.88      0.13      0.22     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.87      0.56      0.57     84972\n",
      "weighted avg       0.86      0.86      0.81     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.561\n",
      "0.8769594690015534\n",
      "0.3276395174994797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     69883\n",
      "           1       0.72      0.50      0.59     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.81      0.73      0.76     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.730\n",
      "0.9382267099750506\n",
      "0.15583562368216952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:21,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     77546\n",
      "           1       0.73      0.47      0.57      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.84      0.72      0.77     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.725\n",
      "0.9560561126017982\n",
      "0.11821778114132658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:32,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.77      0.69      0.73      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.87      0.84      0.85     84972\n",
      "weighted avg       0.95      0.96      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.835\n",
      "0.9706962293461375\n",
      "0.07975357554417592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:45,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     81981\n",
      "           1       0.85      0.20      0.33      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.91      0.60      0.66     84972\n",
      "weighted avg       0.97      0.97      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"HistGradientBoostingClassifier\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    #DecisionTreeClassifier(max_depth=5),\n",
    "    #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    HistGradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\\n-------------\"'-------------')\n",
    "    \n",
    "    # Boucle sur les plis\n",
    "    for train_index, test_index in tqdm(tscv.split(X2)):\n",
    "        X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "\n",
    "        # Entrainer un modèle sur le jeu d'entraînement\n",
    "\n",
    "        model =make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "        #model.set_params(class_weight='balanced_subsample')\n",
    "\n",
    "        model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "        # Prédire sur le jeu de test\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Afficher la précision\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"The balanced accuracy of the default model is \"\n",
    "              f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34c371-cd83-46fc-b0ed-93c26cb83121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(), n_jobs=5,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: (0.01, 0.1, 1, 10),\n",
       "                          &#x27;max_leaf_nodes&#x27;: (3, 10, 30)}],\n",
       "             refit=False,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;log_loss&#x27;: make_scorer(log_loss)},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(), n_jobs=5,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: (0.01, 0.1, 1, 10),\n",
       "                          &#x27;max_leaf_nodes&#x27;: (3, 10, 30)}],\n",
       "             refit=False,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;log_loss&#x27;: make_scorer(log_loss)},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(), n_jobs=5,\n",
       "             param_grid=[{'learning_rate': (0.01, 0.1, 1, 10),\n",
       "                          'max_leaf_nodes': (3, 10, 30)}],\n",
       "             refit=False,\n",
       "             scoring={'f1': make_scorer(f1_score),\n",
       "                      'log_loss': make_scorer(log_loss)},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "#parameters to tune\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'classifier__max_leaf_nodes': (3, 10, 30)}\n",
    "param_grid = [    \n",
    "    {\n",
    "    'learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'max_leaf_nodes': (3, 10, 30)}\n",
    "]\n",
    "\n",
    "classifier = HistGradientBoostingClassifier()\n",
    "model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "logloss_score = make_scorer(log_loss)\n",
    "f1_score_score = make_scorer(f1_score)\n",
    "\n",
    "'''n_jobs=5, \n",
    "cv=5, scoring=’f1_micro’,\n",
    "verbose=2, refit=True'''\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gsearch = GridSearchCV(estimator=classifier, cv=tscv,\n",
    "                        param_grid=param_grid, scoring={'log_loss':logloss_score,'f1':f1_score_score}, refit=False, verbose=2, n_jobs=5)\n",
    "gsearch.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60080172-1bbe-4bf2-b3e1-1c61ecc60d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  9, 12, 11, 10,  5,  7,  4,  1,  3,  2], dtype=int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['rank_test_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e34adb8e-4a14-4186-9b1d-6bfde89e1514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  8,  7,  1,  3,  5,  6,  2,  4, 10, 12, 11], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_['rank_test_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffd84708-ec10-42d2-8b62-f7e7a0537b6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([21.32031889, 22.79760489, 31.22220421, 18.36002054, 19.65783143,\n",
       "        23.98173542,  7.54054232,  7.15282102,  8.94424133,  9.12849617,\n",
       "         8.53568702,  8.09240036]),\n",
       " 'std_fit_time': array([ 9.25405221,  8.97842663, 13.82209018,  6.54679239,  8.39154947,\n",
       "         8.90217315,  2.79415043,  3.0066012 ,  4.32680582,  4.48426112,\n",
       "         3.16644978,  2.9647645 ]),\n",
       " 'mean_score_time': array([0.78166718, 0.94754281, 1.01313682, 0.78056622, 0.8979197 ,\n",
       "        1.08790193, 0.19442196, 0.17828484, 0.3164794 , 0.33921385,\n",
       "        0.29653606, 0.17395239]),\n",
       " 'std_score_time': array([0.22979651, 0.19204853, 0.24796965, 0.19979595, 0.28748257,\n",
       "        0.36173045, 0.04572059, 0.0539238 , 0.16812724, 0.18390421,\n",
       "        0.1425145 , 0.04837183]),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_leaf_nodes': masked_array(data=[3, 10, 30, 3, 10, 30, 3, 10, 30, 3, 10, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.01, 'max_leaf_nodes': 3},\n",
       "  {'learning_rate': 0.01, 'max_leaf_nodes': 10},\n",
       "  {'learning_rate': 0.01, 'max_leaf_nodes': 30},\n",
       "  {'learning_rate': 0.1, 'max_leaf_nodes': 3},\n",
       "  {'learning_rate': 0.1, 'max_leaf_nodes': 10},\n",
       "  {'learning_rate': 0.1, 'max_leaf_nodes': 30},\n",
       "  {'learning_rate': 1, 'max_leaf_nodes': 3},\n",
       "  {'learning_rate': 1, 'max_leaf_nodes': 10},\n",
       "  {'learning_rate': 1, 'max_leaf_nodes': 30},\n",
       "  {'learning_rate': 10, 'max_leaf_nodes': 3},\n",
       "  {'learning_rate': 10, 'max_leaf_nodes': 10},\n",
       "  {'learning_rate': 10, 'max_leaf_nodes': 30}],\n",
       " 'split0_test_log_loss': array([ 5.42063087,  5.69592545,  5.67259541,  3.80449474,  4.22189053,\n",
       "         5.22211337,  7.73115411,  5.56824646,  9.49320909, 30.89153017,\n",
       "        25.25286938, 26.04566687]),\n",
       " 'split1_test_log_loss': array([ 5.47238117,  4.93748677,  4.71521502,  4.40047145,  4.38392833,\n",
       "         4.44373809,  5.24756433,  5.18478529,  5.61702747, 30.25822538,\n",
       "         6.78268156,  7.39859486]),\n",
       " 'split2_test_log_loss': array([ 2.73513013,  2.56121521,  2.54509627,  2.20278082,  2.2719226 ,\n",
       "         2.25919712,  2.5836969 ,  3.05157043,  2.96758225, 33.08794825,\n",
       "         3.44818126,  3.58137464]),\n",
       " 'split3_test_log_loss': array([ 2.66513998,  2.17351222,  1.89694509,  1.68400537,  1.58941262,\n",
       "         1.62080214,  2.41529636,  1.9016111 ,  1.92451696, 33.35645591,\n",
       "         3.06090245,  3.20173111]),\n",
       " 'split4_test_log_loss': array([ 1.14614169,  1.06766789,  1.10457178,  0.81527917,  1.01506923,\n",
       "         1.05366986,  1.26873049,  1.19577106,  1.17922794, 34.83685357,\n",
       "         1.26873049,  1.24200698]),\n",
       " 'mean_test_log_loss': array([ 3.48788477,  3.28716151,  3.18688471,  2.58140631,  2.69644466,\n",
       "         2.91990412,  3.84928844,  3.38039687,  4.23631274, 32.48620266,\n",
       "         7.96267303,  8.29387489]),\n",
       " 'std_test_log_loss': array([1.69711771, 1.74465366, 1.72779715, 1.33212868, 1.37166676,\n",
       "        1.62660797, 2.33843499, 1.73839164, 3.0279094 , 1.68237102,\n",
       "        8.82677888, 9.09718718]),\n",
       " 'rank_test_log_loss': array([ 6,  8,  9, 12, 11, 10,  5,  7,  4,  1,  3,  2], dtype=int32),\n",
       " 'split0_test_f1': array([0.15275476, 0.05741963, 0.08422927, 0.57830646, 0.48104698,\n",
       "        0.21780291, 0.42872367, 0.43357066, 0.40557769, 0.0963395 ,\n",
       "        0.05206758, 0.08226467]),\n",
       " 'split1_test_f1': array([0.28790639, 0.43013806, 0.48191648, 0.61259243, 0.59507111,\n",
       "        0.56200351, 0.56812707, 0.58090177, 0.57546807, 0.13616382,\n",
       "        0.06293952, 0.13275656]),\n",
       " 'split2_test_f1': array([0.24760793, 0.3422658 , 0.35787671, 0.56188307, 0.54679303,\n",
       "        0.55771467, 0.53178569, 0.48207343, 0.49942759, 0.07347666,\n",
       "        0.08178019, 0.0671749 ]),\n",
       " 'split3_test_f1': array([0.2671177 , 0.47746278, 0.57811321, 0.69956107, 0.73087697,\n",
       "        0.73021253, 0.60192953, 0.68149201, 0.68177036, 0.05257768,\n",
       "        0.        , 0.03871625]),\n",
       " 'split4_test_f1': array([0.17621951, 0.28106255, 0.25727325, 0.5725089 , 0.36609272,\n",
       "        0.32131148, 0.        , 0.55932468, 0.51769604, 0.02673524,\n",
       "        0.        , 0.04125737]),\n",
       " 'mean_test_f1': array([0.22632126, 0.31766976, 0.35188178, 0.60497038, 0.54397616,\n",
       "        0.47780902, 0.42611319, 0.54747251, 0.53598795, 0.07705858,\n",
       "        0.03935746, 0.07243395]),\n",
       " 'std_test_f1': array([0.05259737, 0.14687281, 0.17246116, 0.05025281, 0.12095713,\n",
       "        0.18399772, 0.22082811, 0.08540478, 0.09109257, 0.03744267,\n",
       "        0.03351229, 0.03426946]),\n",
       " 'rank_test_f1': array([ 9,  8,  7,  1,  3,  5,  6,  2,  4, 10, 12, 11], dtype=int32)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce41af7-5567-4b63-ba82-5723ebc78821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a82c36f-66e0-4927-9ef1-41178a1dd079",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8951419291060585\n",
      "0.25419369046321016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     71206\n",
      "           1       0.81      0.46      0.59     13766\n",
      "\n",
      "    accuracy                           0.90     84972\n",
      "   macro avg       0.86      0.72      0.76     84972\n",
      "weighted avg       0.89      0.90      0.88     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.722\n",
      "0.8777479640352116\n",
      "0.28319395401783853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     69883\n",
      "           1       0.70      0.55      0.62     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.80      0.75      0.77     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.750\n",
      "0.9393211881560984\n",
      "0.15397330444155394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     77546\n",
      "           1       0.75      0.46      0.57      7426\n",
      "\n",
      "    accuracy                           0.94     84972\n",
      "   macro avg       0.85      0.72      0.77     84972\n",
      "weighted avg       0.93      0.94      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.721\n",
      "0.9534317186838017\n",
      "0.12895073421802777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     77756\n",
      "           1       0.77      0.64      0.70      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.87      0.81      0.84     84972\n",
      "weighted avg       0.95      0.95      0.95     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.812\n",
      "0.9769453467024432\n",
      "0.06437896847960296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     81981\n",
      "           1       0.85      0.42      0.56      2991\n",
      "\n",
      "    accuracy                           0.98     84972\n",
      "   macro avg       0.92      0.71      0.77     84972\n",
      "weighted avg       0.97      0.98      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.707\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=   7.6s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=   5.9s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  19.7s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  33.2s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  18.0s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  22.4s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=   7.7s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  16.6s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  14.2s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=  13.8s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  32.9s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=   8.5s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=  13.4s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  18.8s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  22.6s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  30.1s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  50.6s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  31.4s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=   7.9s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   2.8s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   5.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=  11.6s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=   5.8s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  14.6s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=   6.3s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  17.5s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  25.4s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  43.9s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  31.5s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  20.2s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   3.3s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   6.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=  28.6s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=   7.1s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  18.6s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=   8.8s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=   5.8s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  21.4s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  15.3s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  18.9s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  12.4s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  42.3s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  16.1s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  11.5s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  31.5s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   8.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=   9.7s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  13.8s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=  13.1s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  26.7s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=   8.7s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  39.1s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  13.0s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  10.5s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  38.0s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  11.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=   2.9s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  23.0s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  29.5s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=  16.9s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  21.5s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  34.2s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  20.3s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=   7.0s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  18.0s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  25.9s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  19.5s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  36.6s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=   2.5s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  10.6s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=   9.6s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=   9.5s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  12.5s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  13.9s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  16.7s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=   8.8s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  14.3s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  21.9s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  17.2s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time= 1.2min\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  10.3s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  24.9s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  11.6s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=   8.5s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=   8.8s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  27.3s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=30; total time=  35.5s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  21.5s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  27.0s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=   3.9s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=   5.3s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  11.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   9.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  12.3s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=   4.2s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=   6.4s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=   3.4s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  10.6s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  21.8s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  31.2s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  19.3s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=   6.3s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  18.7s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  45.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=10; total time=   8.3s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  32.4s\n",
      "[CV] END .................learning_rate=10, max_leaf_nodes=3; total time=  21.1s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=  28.7s\n",
      "[CV] END ...............learning_rate=0.01, max_leaf_nodes=3; total time=  29.9s\n",
      "[CV] END ..............learning_rate=0.01, max_leaf_nodes=10; total time=  33.5s\n",
      "[CV] END ................learning_rate=0.1, max_leaf_nodes=3; total time=  23.2s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=   7.1s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=10; total time=  21.1s\n",
      "[CV] END ...............learning_rate=0.1, max_leaf_nodes=30; total time=  26.2s\n",
      "[CV] END ..................learning_rate=1, max_leaf_nodes=3; total time=  10.5s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=   2.8s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=   6.1s\n",
      "[CV] END .................learning_rate=1, max_leaf_nodes=30; total time=  15.5s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=10; total time=  10.9s\n",
      "[CV] END ................learning_rate=10, max_leaf_nodes=30; total time=  11.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier(learning_rate= 0.1, max_leaf_nodes= 3)\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6821b134-441e-4306-ba8d-ff648d49a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1422939321188156\n",
      "30.914860220451995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.12      0.18     71206\n",
      "           1       0.06      0.28      0.10     13766\n",
      "\n",
      "    accuracy                           0.14     84972\n",
      "   macro avg       0.26      0.20      0.14     84972\n",
      "weighted avg       0.39      0.14      0.17     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.199\n",
      "0.15674575154168433\n",
      "30.393963850332007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.11      0.17     69883\n",
      "           1       0.09      0.39      0.14     15089\n",
      "\n",
      "    accuracy                           0.16     84972\n",
      "   macro avg       0.27      0.25      0.16     84972\n",
      "weighted avg       0.38      0.16      0.17     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.248\n",
      "0.0821917808219178\n",
      "33.081161329737654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.05      0.09     77546\n",
      "           1       0.04      0.41      0.07      7426\n",
      "\n",
      "    accuracy                           0.08     84972\n",
      "   macro avg       0.26      0.23      0.08     84972\n",
      "weighted avg       0.44      0.08      0.09     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.232\n",
      "0.07449512780680695\n",
      "33.35857682327061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.05      0.10     77756\n",
      "           1       0.03      0.30      0.05      7216\n",
      "\n",
      "    accuracy                           0.07     84972\n",
      "   macro avg       0.24      0.18      0.07     84972\n",
      "weighted avg       0.42      0.07      0.09     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.178\n",
      "0.033481617473991435\n",
      "34.83685357397759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.02      0.04     81981\n",
      "           1       0.01      0.38      0.03      2991\n",
      "\n",
      "    accuracy                           0.03     84972\n",
      "   macro avg       0.25      0.20      0.03     84972\n",
      "weighted avg       0.46      0.03      0.04     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier(learning_rate= 10, max_leaf_nodes= 3)\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edbaaa7b-950c-42ce-bb1b-cd2e427dad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851268653203408\n",
      "0.28725729516608145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     71206\n",
      "           1       0.70      0.52      0.59     13766\n",
      "\n",
      "    accuracy                           0.89     84972\n",
      "   macro avg       0.80      0.74      0.76     84972\n",
      "weighted avg       0.88      0.89      0.88     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.736\n",
      "0.8624605752483171\n",
      "0.3438494831791435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     69883\n",
      "           1       0.67      0.45      0.54     15089\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.78      0.70      0.73     84972\n",
      "weighted avg       0.85      0.86      0.85     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.699\n",
      "0.9313773949065575\n",
      "0.18612147209597016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     77546\n",
      "           1       0.69      0.39      0.50      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.82      0.69      0.73     84972\n",
      "weighted avg       0.92      0.93      0.92     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.689\n",
      "0.9471119898319447\n",
      "0.15194905919248516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     77756\n",
      "           1       0.73      0.60      0.66      7216\n",
      "\n",
      "    accuracy                           0.95     84972\n",
      "   macro avg       0.85      0.79      0.81     84972\n",
      "weighted avg       0.94      0.95      0.94     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.788\n",
      "0.9684955044014499\n",
      "0.09509832672808588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     81981\n",
      "           1       0.65      0.22      0.33      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.81      0.61      0.66     84972\n",
      "weighted avg       0.96      0.97      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.610\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    \n",
    "    classifier = HistGradientBoostingClassifier()\n",
    "    model =make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd1a9e08-b152-49fa-b397-9af7b346bfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8638728051593466\n",
      "0.31891108273695173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     71206\n",
      "           1       0.89      0.18      0.30     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.88      0.59      0.61     84972\n",
      "weighted avg       0.87      0.86      0.82     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.589\n",
      "0.8765240314456527\n",
      "0.33581097815950334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     69883\n",
      "           1       0.72      0.50      0.59     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.81      0.73      0.76     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.729\n",
      "0.9330956079649767\n",
      "0.3663570620000026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     77546\n",
      "           1       0.61      0.66      0.63      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.79      0.81      0.80     84972\n",
      "weighted avg       0.94      0.93      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.812\n",
      "0.9578684743209528\n",
      "0.23192212079971924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.77      0.72      0.74      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.87      0.85      0.86     84972\n",
      "weighted avg       0.96      0.96      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.850\n",
      "0.9730734830297039\n",
      "0.1759191398739803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     81981\n",
      "           1       0.88      0.27      0.42      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.93      0.64      0.70     84972\n",
      "weighted avg       0.97      0.97      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    model1 = MLPClassifier(alpha=1, max_iter=1000)\n",
    "    model2 = AdaBoostClassifier()\n",
    "    model3 = HistGradientBoostingClassifier()\n",
    "    model4 = LogisticRegression()\n",
    "    model5 = RandomForestClassifier()\n",
    "    model6 = KNeighborsClassifier()\n",
    "\n",
    "    model7 = VotingClassifier([('MLP', make_pipeline(StandardScaler(), model1)), \n",
    "                                 ('Ada', make_pipeline(StandardScaler(), model2)), \n",
    "                                 ('HGB', make_pipeline(StandardScaler(), model3)),\n",
    "                                 ('LR', make_pipeline(StandardScaler(), model4))], \n",
    "                               voting='soft')\n",
    "    \n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model7.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model7.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model7.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93659fd4-ce8d-4037-a0bd-1e50ab2fa201",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622958150920303\n",
      "0.3738313741617672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     71206\n",
      "           1       0.85      0.18      0.30     13766\n",
      "\n",
      "    accuracy                           0.86     84972\n",
      "   macro avg       0.86      0.59      0.61     84972\n",
      "weighted avg       0.86      0.86      0.82     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.588\n",
      "0.8716989125829685\n",
      "0.31240270352139465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     69883\n",
      "           1       0.68      0.52      0.59     15089\n",
      "\n",
      "    accuracy                           0.87     84972\n",
      "   macro avg       0.79      0.73      0.76     84972\n",
      "weighted avg       0.86      0.87      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 49\u001b[0m\n\u001b[1;32m     41\u001b[0m model7 \u001b[38;5;241m=\u001b[39m StackingClassifier([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, make_pipeline(StandardScaler(), model1)), \n\u001b[1;32m     42\u001b[0m                              (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAda\u001b[39m\u001b[38;5;124m'\u001b[39m, make_pipeline(StandardScaler(), model2)), \n\u001b[1;32m     43\u001b[0m                              (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHGB\u001b[39m\u001b[38;5;124m'\u001b[39m, make_pipeline(StandardScaler(), model3))],                                 \n\u001b[1;32m     44\u001b[0m                            final_estimator\u001b[38;5;241m=\u001b[39mLogisticRegression())\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#model.set_params(class_weight='balanced_subsample')\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mmodel7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, sample_weight=0.3)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Prédire sur le jeu de test\u001b[39;00m\n\u001b[1;32m     52\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model7\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:660\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    659\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:253\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[1;32m    250\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     )\n\u001b[0;32m--> 253\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    271\u001b[0m     meth\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:968\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 968\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    976\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1050\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1050\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m   1052\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:578\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    576\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 578\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    model1 = MLPClassifier(alpha=1, max_iter=1000)\n",
    "    model2 = AdaBoostClassifier()\n",
    "    model3 = HistGradientBoostingClassifier()\n",
    "    model4 = LogisticRegression()\n",
    "    model5 = RandomForestClassifier()\n",
    "    model6 = KNeighborsClassifier()\n",
    "\n",
    "    model7 = StackingClassifier([('MLP', make_pipeline(StandardScaler(), model1)), \n",
    "                                 ('Ada', make_pipeline(StandardScaler(), model2)), \n",
    "                                 ('HGB', make_pipeline(StandardScaler(), model3))],                                 \n",
    "                               final_estimator=LogisticRegression())\n",
    "    \n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model7.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model7.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model7.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fe64d-ec15-4334-a9a5-f7eb2cabf5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e972a34-5ce0-4687-ace8-a45782df5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:21, 1:79} \n",
    "logreg_w = LogisticRegression(class_weight = weights, max_iter = 1000) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "67d9b8aa-e8e4-47e2-9c16-9accfeb90e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797015487454691\n",
      "0.2906810638095818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     71206\n",
      "           1       0.83      0.32      0.47     13766\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.86      0.66      0.70     84972\n",
      "weighted avg       0.87      0.88      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.655\n",
      "0.8772772207315351\n",
      "0.2881136429049193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     69883\n",
      "           1       0.74      0.48      0.58     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.82      0.72      0.75     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.720\n",
      "0.934260697641576\n",
      "0.2996039312531464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     77546\n",
      "           1       0.62      0.63      0.62      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.79      0.79      0.79     84972\n",
      "weighted avg       0.93      0.93      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.795\n",
      "0.9583509862072213\n",
      "0.13895192285658137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.79      0.69      0.74      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.88      0.84      0.86     84972\n",
      "weighted avg       0.96      0.96      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.836\n",
      "0.9723320623264134\n",
      "0.0807127304781807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     81981\n",
      "           1       0.82      0.27      0.41      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.90      0.64      0.70     84972\n",
      "weighted avg       0.97      0.97      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNetCV\n",
    "\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    weights = {0:21, 1:79} \n",
    "    classifier = LogisticRegression(class_weight = weights)\n",
    "\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2a1976d-fb80-4a35-81f5-be34d17608ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797015487454691\n",
      "0.2906810638095818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     71206\n",
      "           1       0.83      0.32      0.47     13766\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.86      0.66      0.70     84972\n",
      "weighted avg       0.87      0.88      0.86     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.655\n",
      "0.8772772207315351\n",
      "0.2881136429049193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     69883\n",
      "           1       0.74      0.48      0.58     15089\n",
      "\n",
      "    accuracy                           0.88     84972\n",
      "   macro avg       0.82      0.72      0.75     84972\n",
      "weighted avg       0.87      0.88      0.87     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.720\n",
      "0.934260697641576\n",
      "0.2996039312531464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     77546\n",
      "           1       0.62      0.63      0.62      7426\n",
      "\n",
      "    accuracy                           0.93     84972\n",
      "   macro avg       0.79      0.79      0.79     84972\n",
      "weighted avg       0.93      0.93      0.93     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.795\n",
      "0.9583509862072213\n",
      "0.13895192285658137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     77756\n",
      "           1       0.79      0.69      0.74      7216\n",
      "\n",
      "    accuracy                           0.96     84972\n",
      "   macro avg       0.88      0.84      0.86     84972\n",
      "weighted avg       0.96      0.96      0.96     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.836\n",
      "0.9723320623264134\n",
      "0.0807127304781807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     81981\n",
      "           1       0.82      0.27      0.41      2991\n",
      "\n",
      "    accuracy                           0.97     84972\n",
      "   macro avg       0.90      0.64      0.70     84972\n",
      "weighted avg       0.97      0.97      0.97     84972\n",
      "\n",
      "The balanced accuracy of the default model is 0.636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNetCV\n",
    "\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1)\n",
    "y = df['target']\n",
    "X2 = X.fillna(0)\n",
    "# Créer un objet TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Boucle sur les plis\n",
    "for train_index, test_index in tscv.split(X2):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data_train['target']), y=data_train['target'])))\n",
    "    \n",
    "    # Entrainer un modèle sur le jeu d'entraînement\n",
    "    model1 = LogisticRegression(penalty='elasticnet', solver = 'saga')\n",
    "    model2 = LogisticRegression(penalty='l1', solver = 'saga')\n",
    "    model3 = HistGradientBoostingClassifier()\n",
    "    model4 = LogisticRegression(penalty='l2')\n",
    "    model5 = RandomForestClassifier()\n",
    "    model6 = KNeighborsClassifier()\n",
    "\n",
    "    model7 = VotingClassifier([#('Elastic', make_pipeline(StandardScaler(), model1)), \n",
    "                                 ('Lasso', make_pipeline(StandardScaler(), model2)), \n",
    "                                 ('HGB', make_pipeline(StandardScaler(), model3)),\n",
    "                                 ('Ridge', make_pipeline(StandardScaler(), model4))], \n",
    "                               voting='soft')\n",
    "    \n",
    "    \n",
    "    #model.set_params(class_weight='balanced_subsample')\n",
    "    \n",
    "    model7.fit(X_train, y_train)#, sample_weight=0.3)\n",
    "\n",
    "    # Prédire sur le jeu de test\n",
    "    y_pred = model7.predict(X_test)\n",
    "\n",
    "    # Afficher la précision\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(log_loss(y_test, model7.predict_proba(X_test)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"The balanced accuracy of the default model is \"\n",
    "          f\"{balanced_accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0afb2-c348-49f5-877c-b1b161cde3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5e1d4-022a-472c-9a23-b899937bf369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f962dd-4e4f-4b27-8f72-0f5ae7ec0187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e19dfab-4018-4c4d-bfd9-199c73c98bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509834, 73)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ddbd6a2-fdbf-4d67-b79f-b6b720bfcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509834,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3d3ac4-c73b-416e-9342-7bb6cf5d4b74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(),\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.01, 0.1, 0.5, 0.9]}], refit=False,\n",
       "             scoring=&lt;function f1_score at 0x7f9b08c5f280&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(),\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.01, 0.1, 0.5, 0.9]}], refit=False,\n",
       "             scoring=&lt;function f1_score at 0x7f9b08c5f280&gt;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=HistGradientBoostingClassifier(),\n",
       "             param_grid=[{'learning_rate': [0.01, 0.1, 0.5, 0.9]}], refit=False,\n",
       "             scoring=<function f1_score at 0x7f9b08c5f280>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer, f1_score\n",
    "\n",
    "X = df.drop(columns=['target'], axis=1).copy()\n",
    "y = df['target']\n",
    "X2 = X.fillna(0).copy()\n",
    "#parameters to tune\n",
    "param_grid = [    \n",
    "    {'learning_rate' : [0.01, 0.1, 0.5, 0.9]\n",
    "    #'max_iter': [100,1000,5000]\n",
    "    #'max_leaf_nodes': [20,31,50],\n",
    "    #'l2_regularization' : [0,0.1,0.5,0.9],\n",
    "    #'max_iter' : [100, 1000,2500, 5000],\n",
    "    #'warm_start' : [True,False]\n",
    "    }\n",
    "]\n",
    "\n",
    "classifier = HistGradientBoostingClassifier()\n",
    "model = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "\n",
    "logloss_score = make_scorer(log_loss)\n",
    "f1_score_score = make_scorer(f1_score)\n",
    "\n",
    "'''n_jobs=5, \n",
    "cv=5, scoring=’f1_micro’,\n",
    "verbose=2, refit=True'''\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gsearch = GridSearchCV(estimator=classifier, cv=tscv,\n",
    "                        param_grid=param_grid, scoring=f1_score, refit=False)#{'log_loss':logloss_score,'f1':f1_score_score}, refit=False)#, verbose=2, n_jobs=5)\n",
    "gsearch.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dac78c41-97df-4ac2-bcc1-1779285473cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([11.81362991, 10.73984299,  5.16959763,  4.81388669]),\n",
       " 'std_fit_time': array([4.37527214, 3.86276233, 1.79743632, 2.27879971]),\n",
       " 'mean_score_time': array([0.00025172, 0.0002378 , 0.0002183 , 0.00021968]),\n",
       " 'std_score_time': array([2.72646631e-05, 2.29013921e-05, 9.63234665e-06, 7.24510088e-06]),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.1, 0.5, 0.9],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.01},\n",
       "  {'learning_rate': 0.1},\n",
       "  {'learning_rate': 0.5},\n",
       "  {'learning_rate': 0.9}],\n",
       " 'split0_test_score': array([nan, nan, nan, nan]),\n",
       " 'split1_test_score': array([nan, nan, nan, nan]),\n",
       " 'split2_test_score': array([nan, nan, nan, nan]),\n",
       " 'split3_test_score': array([nan, nan, nan, nan]),\n",
       " 'split4_test_score': array([nan, nan, nan, nan]),\n",
       " 'mean_test_score': array([nan, nan, nan, nan]),\n",
       " 'std_test_score': array([nan, nan, nan, nan]),\n",
       " 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4826a-f1d9-4442-9b34-4576a794504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
