{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Author : [Alexandre Gramfort](http://alexandre.gramfort.net)\n",
    "         \n",
    "         \n",
    "with some code snippets from [Olivier Grisel](http://ogrisel.com/) (leaf encoder)\n",
    "\n",
    "It is the most creative aspect of Data Science!\n",
    "\n",
    "We will use here the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dtypes of the different columns. You will observe that it contains columns that\n",
    "are explicitly marked as `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'deck']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "make_column_selector(dtype_include='category')(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to get quickly the names of the columns to treat as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data contains both quantitative and categorical variables. These categorical have some predictive power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f99754319d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 430.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(data=df, x='pclass', y='survived', hue='sex', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is how to feed these non-quantitative features to a supervised learning model?\n",
    "\n",
    "## Categorical features\n",
    "\n",
    " - Nearly always need some treatment\n",
    " - High cardinality can create very sparse data\n",
    " - Difficult to impute missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding\n",
    "\n",
    "**Idea:** Each category is coded as a 0 or 1 in a dedicated column.\n",
    "\n",
    " - It is the most basic method. It is used with most linear algorithms\n",
    " - Drop first column to avoid collinearity\n",
    " - It uses sparse format which is memory-friendly\n",
    " - Most current implementations don’t gracefully treat missing, unseen variables\n",
    "\n",
    "Example with the `embarked` column. We have here 3 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked\n",
       "0        S\n",
       "1        C\n",
       "2        S\n",
       "3        S\n",
       "4        S\n",
       "5        Q\n",
       "6        S\n",
       "7        S\n",
       "8        S\n",
       "9        C"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a [scikit-learn OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(df1.head(10)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know which column corresponds to what you can look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the first column will be a 1 if category was 'C', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(df1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now 4 columns, one corresponding to NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S', nan], dtype=object)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the columns are linearly dependant after one-hot encoding you can drop one column with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe2 = OneHotEncoder(drop='first')\n",
    "ohe2.fit_transform(df1.head(10)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe2.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This avoids colinearity, which for example leads to slower optimization solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal encoding\n",
    "\n",
    "**Idea:** Each category is coded with a different integer. The order being arbitrary.\n",
    "\n",
    " - Give every categorical variable a unique numerical ID\n",
    " - Useful for non-linear tree-based algorithms (forests, gradient-boosting)\n",
    " - Does not increase dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    embarked\n",
       "0          S\n",
       "1          C\n",
       "2          S\n",
       "3          S\n",
       "4          S\n",
       "..       ...\n",
       "886        S\n",
       "887        S\n",
       "888        S\n",
       "889        C\n",
       "890        Q\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit_transform(df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 'C' will be coded as 0, 'Q' as a 1 and 'S' as a 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count encoding\n",
    "\n",
    "**Idea:** Replace categorical variables with their count in the train set\n",
    "\n",
    "- Useful for both linear and non-linear algorithms\n",
    "- Can be sensitive to outliers\n",
    "- May add log-transform, works well with counts\n",
    "- Replace unseen variables with `1`\n",
    "- May give collisions: same encoding, different variables\n",
    "\n",
    "You'll need to install the `category_encoders` package with:\n",
    "\n",
    "    pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1.post0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked\n",
       "0        S\n",
       "1        C\n",
       "2        S\n",
       "3        S\n",
       "4        S\n",
       "5        Q\n",
       "6        S\n",
       "7        S\n",
       "8        S\n",
       "9        C"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [2],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.CountEncoder().fit_transform(df1.head(10)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'S' is replaced by 7 as it appears 7 times in the fitted data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label / Ordinal count encoding\n",
    "\n",
    "**Idea:** Rank categorical variables by count and use this rank as encoding value. It is an ordinal encoding where the value is taking from the frequence of each category.\n",
    "\n",
    "- Useful for both linear and non-linear algorithms\n",
    "- Not sensitive to outliers\n",
    "- Won’t give same encoding to different variables\n",
    "- Best of both worlds\n",
    "\n",
    "As it is not available in any package we will implement this ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "class CountOrdinalEncoder(OrdinalEncoder):\n",
    "    \"\"\"Encode categorical features as an integer array\n",
    "    usint count information.\n",
    "    \"\"\"\n",
    "    def __init__(self, categories='auto', dtype=np.float64):\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the OrdinalEncoder to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to determine the categories of each feature.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.handle_unknown = 'use_encoded_value'\n",
    "        self.unknown_value = np.nan\n",
    "        super().fit(X)\n",
    "        X_list, _, _ = self._check_X(X)\n",
    "        # now we'll reorder by counts\n",
    "        for k, cat in enumerate(self.categories_):\n",
    "            counts = []\n",
    "            for c in cat:\n",
    "                counts.append(np.sum(X_list[k] == c))\n",
    "            order = np.argsort(counts)\n",
    "            self.categories_[k] = cat[order]\n",
    "        return self\n",
    "\n",
    "coe = CountOrdinalEncoder()\n",
    "coe.fit_transform(pd.DataFrame(df1.head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'S' is replace by 2 as it's the most frequent, then 'C' is 1 and 'Q' is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encoding is robust to collision which can happen with the CountEncoder when certain categories happen the same number of times. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coe.fit_transform(pd.DataFrame(['es', 'fr', 'fr', 'en', 'en', 'es']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  2\n",
       "1  2\n",
       "2  2\n",
       "3  2\n",
       "4  2\n",
       "5  2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.CountEncoder().fit_transform(pd.DataFrame(['es', 'fr', 'fr', 'en', 'en', 'es']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash encoding\n",
    "\n",
    "**Idea:** Does “OneHot-encoding” with arrays of a fixed length.\n",
    "\n",
    "- Avoids extremely sparse data\n",
    "- May introduce collisions\n",
    "- Can repeat with different hash functions and bag result for small bump in accuracy\n",
    "- Collisions usually degrade results, but may improve it.\n",
    "- Gracefully deals with new variables (eg: new user-agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked\n",
       "0        S\n",
       "1        C\n",
       "2        S\n",
       "3        S\n",
       "4        S\n",
       "5        Q\n",
       "6        S\n",
       "7        S\n",
       "8        S\n",
       "9        C"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3\n",
       "0      0      0      1      0\n",
       "1      0      0      0      1\n",
       "2      0      0      1      0\n",
       "3      0      0      1      0\n",
       "4      0      0      1      0\n",
       "5      0      0      1      0\n",
       "6      0      0      1      0\n",
       "7      0      0      1      0\n",
       "8      0      0      1      0\n",
       "9      0      0      0      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.hashing.HashingEncoder(n_components=4).fit_transform(df1.head(10).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "\n",
    "Encode categorical variables by their ratio of target (binary classification or regression)\n",
    "\n",
    "Formula reads:\n",
    "\n",
    "$$\n",
    "    TE(X) = \\alpha(n(X)) E[ y | x=X ] +  (1 - \\alpha(n(X))) E[y]\n",
    "$$\n",
    "\n",
    "where $n(X)$ is the count of category $X$ and $\\alpha$ is a monotonically increasing function bounded between 0 and 1.[1].\n",
    "\n",
    "- Add smoothing to avoid setting variable encodings to 0.\n",
    "```\n",
    "[1] Micci-Barreca, 2001: A preprocessing scheme for\n",
    "high-cardinality categorical attributes in classification\n",
    "and prediction problems.\n",
    "```\n",
    "\n",
    "You will need the [dirty cat](https://pypi.org/project/dirty-cat/) package. You can install it with:\n",
    "\n",
    "    pip install dirty_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58333333],\n",
       "       [0.66666667],\n",
       "       [0.77777778],\n",
       "       [0.58333333],\n",
       "       [0.66666667],\n",
       "       [0.66666667]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dirty_cat as dc  # install with: pip install dirty_cat\n",
    "\n",
    "X = np.array(['A', 'B', 'C', 'A', 'B', 'B'])[:, np.newaxis]\n",
    "y = np.array([1  , 1  , 1  , 0  , 0  , 1])\n",
    "\n",
    "dc.TargetEncoder(clf_type='binary-clf').fit_transform(X, y)\n",
    "# If \\alpha was 1 you would get: [0.5, 0.66, 1, 0.5, 0.66, 0.66]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN encoding\n",
    "\n",
    "It is quite frequent in real life that the fact one variable is missing\n",
    "has some predictive power. For example in the Titanic dataset the 'deck'\n",
    "parameter is very often missing and it is missing often for passengers who\n",
    "did not have a proper cabin and there who were most likely to die.\n",
    "\n",
    "To inform your supervised model you can explicit encode the missingness\n",
    "with a dedicated column.\n",
    "\n",
    "You can do this with a [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 1. ],\n",
       "       [2. , 0. ],\n",
       "       [0. , 0. ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = np.array([0, 1., np.nan, 2., 0.])[:, None]\n",
    "SimpleImputer(strategy='median', add_indicator=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or [MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "X = np.array([0, 1., np.nan, 2., 0.])[:, None]\n",
    "MissingIndicator().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial encoding\n",
    "\n",
    "**Idea:** Encode interactions between categorical variables\n",
    "\n",
    "- Linear algorithms without interactions can not solve the XOR problem\n",
    "- A polynomial kernel *can* solve XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 1, 0], [1, 1, 0], [1, 1, 1], [0, 0, 0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "PolynomialFeatures(include_bias=False, interaction_only=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go beyond\n",
    "\n",
    "You can also use some form of embedding eg using a Neural Network to create dense embeddings from categorical variables.\n",
    "\n",
    "- Map categorical variables in a function approximation problem into Euclidean spaces\n",
    "- Faster model training.\n",
    "- Less memory overhead.\n",
    "- Can give better accuracy than 1-hot encoded.\n",
    "- See for example https://arxiv.org/abs/1604.06737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning\n",
    "\n",
    "See https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_classification.html\n",
    "\n",
    "[KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html) allows you to estimate non-linear model in the original feature space while only using a linear logistic regression. \n",
    "\n",
    "See this [example in regression](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html).\n",
    "\n",
    "What it does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KBinsDiscretizer is a preprocessing module in scikit-learn used for binning continuous data into discrete intervals. It can be used for feature discretization, also known as quantization or binning. The resulting discrete feature can be used for further processing, such as for use with algorithms that cannot handle continuous data. The number of bins, the strategy for binning, and the encoding of the discrete values can all be specified as parameters when creating the KBinsDiscretizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ],\n",
       "       [ 0.64768854,  1.52302986],\n",
       "       [-0.23415337, -0.23413696],\n",
       "       [ 1.57921282,  0.76743473],\n",
       "       [-0.46947439,  0.54256004],\n",
       "       [-0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024],\n",
       "       [-1.72491783, -0.56228753],\n",
       "       [-1.01283112,  0.31424733],\n",
       "       [-0.90802408, -1.4123037 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X = rng.randn(10, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KBinsDiscretizer(n_bins=2).fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "\n",
    "Scale to numerical variables into a certain range\n",
    "\n",
    "- Standard (Z) Scaling\n",
    "- MinMax Scaling\n",
    "- Root scaling\n",
    "- Log scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.49671415],\n",
       "       [ 9.8617357 ],\n",
       "       [10.64768854],\n",
       "       [11.52302986],\n",
       "       [ 9.76584663],\n",
       "       [ 9.76586304],\n",
       "       [11.57921282],\n",
       "       [10.76743473],\n",
       "       [ 9.53052561],\n",
       "       [10.54256004]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X = 10 + rng.randn(10, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07093253],\n",
       "       [-0.85481899],\n",
       "       [ 0.29104199],\n",
       "       [ 1.56722474],\n",
       "       [-0.99461815],\n",
       "       [-0.99459421],\n",
       "       [ 1.64913533],\n",
       "       [ 0.46562306],\n",
       "       [-1.33769874],\n",
       "       [ 0.13777244]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4716135 ],\n",
       "       [0.16166943],\n",
       "       [0.54530673],\n",
       "       [0.97257612],\n",
       "       [0.1148643 ],\n",
       "       [0.11487231],\n",
       "       [1.        ],\n",
       "       [0.60375694],\n",
       "       [0.        ],\n",
       "       [0.49399168]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.69314718],\n",
       "       [1.09861229],\n",
       "       [1.38629436],\n",
       "       [1.60943791],\n",
       "       [1.79175947],\n",
       "       [1.94591015],\n",
       "       [2.07944154],\n",
       "       [2.19722458]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X = np.arange(1, 10)[:, np.newaxis]\n",
    "FunctionTransformer(func=np.log).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf coding\n",
    "\n",
    "The following is an implementation of a trick found in:\n",
    "\n",
    "Practical Lessons from Predicting Clicks on Ads at Facebook\n",
    "Junfeng Pan, He Xinran, Ou Jin, Tianbing XU, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, Joaquin Quiñonero Candela\n",
    "International Workshop on Data Mining for Online Advertising (ADKDD)\n",
    "\n",
    "https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x146 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4450 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "class TreeTransform(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"One-hot encode samples with an ensemble of trees\n",
    "    \n",
    "    This transformer first fits an ensemble of trees (e.g. gradient\n",
    "    boosted trees or a random forest) on the training set.\n",
    "\n",
    "    Then each leaf of each tree in the ensembles is assigned a fixed\n",
    "    arbitrary feature index in a new feature space. If you have 100\n",
    "    trees in the ensemble and 2**3 leafs per tree, the new feature\n",
    "    space has 100 * 2**3 == 800 dimensions.\n",
    "    \n",
    "    Each sample of the training set go through the decisions of each tree\n",
    "    of the ensemble and ends up in one leaf per tree. The sample if encoded\n",
    "    by setting features with those leafs to 1 and letting the other feature\n",
    "    values to 0.\n",
    "    \n",
    "    The resulting transformer learn a supervised, sparse, high-dimensional\n",
    "    categorical embedding of the data.\n",
    "    \n",
    "    This transformer is typically meant to be pipelined with a linear model\n",
    "    such as logistic regression, linear support vector machines or\n",
    "    elastic net regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.fit_transform(X, y)\n",
    "        return self\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y)\n",
    "        self.binarizers_ = []\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t in estimators:\n",
    "            lb = LabelBinarizer(sparse_output=True)\n",
    "            X_leafs = t.tree_.apply(X.astype(np.float32))\n",
    "            sparse_applications.append(lb.fit_transform(X_leafs))\n",
    "            self.binarizers_.append(lb)\n",
    "        return hstack(sparse_applications)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t, lb in zip(estimators, self.binarizers_):\n",
    "            X_leafs = t.tree_.apply(X.astype(np.float32))\n",
    "            sparse_applications.append(lb.transform(X_leafs))\n",
    "        return hstack(sparse_applications)\n",
    "\n",
    "\n",
    "boosted_trees = GradientBoostingClassifier(\n",
    "    max_leaf_nodes=5, learning_rate=0.1,\n",
    "    n_estimators=10, random_state=0,\n",
    ")\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "TreeTransform(boosted_trees).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a custom transformer class called \"TreeTransform\", which is intended to be used in combination with an ensemble of trees such as gradient boosted trees or a random forest. The transformer takes in an estimator as an input and fits it on the training data, X and y. Then it applies the decision of each tree of the ensemble to each sample of the training set and assigns the sample to a leaf in each tree. These leafs are used as new features and each sample is encoded by setting the corresponding leaf feature to 1 and the other feature values to 0. This results in a new feature space with dimensions equal to the number of trees in the ensemble multiplied by the number of leafs per tree.\n",
    "The code also uses the LabelBinarizer() to binarize the leafs feature, and it uses the scipy.sparse.hstack() to stack the sparse matrices horizontally.\n",
    "It also uses the Iris dataset to demonstrate the use of the transformer. It fits the dataset into the transformer and returns the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "# Split the data into a train and test set\n",
    "data, target = make_classification(\n",
    "    n_samples=400, n_features=20, n_classes=2,\n",
    "    weights=[.7, .3], random_state=42, flip_y=.2,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  2]\n",
      " [11 16]]\n",
      "Accuracy:  0.8375\n",
      "Score scikit-learn:  0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pierreloviton/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Use the pipeline to make predictions on the test data\n",
    "y_pred = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: \", (y_pred == y_test).mean())\n",
    "print(\"Score scikit-learn: \", lr.score(X_test, y_test))\n",
    "np.mean(cross_val_score(lr, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the TreeTransform transformer\n",
    "tree_transformer = TreeTransform(boosted_trees)\n",
    "\n",
    "# Define a pipeline with the TreeTransform transformer and a logistic regression estimator\n",
    "pipe = Pipeline([\n",
    "    ('tree_transformer', tree_transformer),\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Use the pipeline to make predictions on the test data\n",
    "y_pred = pipe.predict(X_test)\n",
    "np.mean(cross_val_score(pipe, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  3],\n",
       "       [14, 13]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7875\n",
      "Score scikit-learn:  0.7875\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (y_pred == y_test).mean())\n",
    "print(\"Score scikit-learn: \", pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "#ct = make_column_transformer(\n",
    "#    (make_pipeline(SimpleImputer(), StandardScaler()), ['age', 'pclass', 'fare'])\n",
    "#)\n",
    "#y = df.survived.values\n",
    "#X = df.drop(['survived', 'alive'], axis=1)\n",
    "ctt = TreeTransform(GradientBoostingClassifier(\n",
    "    max_leaf_nodes=5, learning_rate=0.1,\n",
    "    n_estimators=10, random_state=0,\n",
    "))\n",
    "clf = make_pipeline(ctt, lr)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Limiting yourself to LogisticRegression propose features to predict survival.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y = df.survived.values\n",
    "X = df.drop(['survived', 'alive'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex   age  sibsp  parch     fare embarked  class    who  \\\n",
       "0       3    male  22.0      1      0   7.2500        S  Third    man   \n",
       "1       1  female  38.0      1      0  71.2833        C  First  woman   \n",
       "2       3  female  26.0      0      0   7.9250        S  Third  woman   \n",
       "3       1  female  35.0      1      0  53.1000        S  First  woman   \n",
       "4       3    male  35.0      0      0   8.0500        S  Third    man   \n",
       "\n",
       "   adult_male deck  embark_town  alone  \n",
       "0        True  NaN  Southampton  False  \n",
       "1       False    C    Cherbourg  False  \n",
       "2       False  NaN  Southampton   True  \n",
       "3       False    C  Southampton  False  \n",
       "4        True  NaN  Southampton   True  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026591760299625"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "ctt = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), ['age', 'pclass', 'fare'])\n",
    ")\n",
    "\n",
    "clf = make_pipeline(ctt, lr)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105368289637954"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "ct = TreeTransform(GradientBoostingClassifier(\n",
    "    max_leaf_nodes=5, learning_rate=0.1,\n",
    "    n_estimators=10, random_state=0,\n",
    "))\n",
    "ctt = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler(), ct), ['age', 'pclass', 'fare'])\n",
    ")\n",
    "\n",
    "clf = make_pipeline(ctt, lr)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do better !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
